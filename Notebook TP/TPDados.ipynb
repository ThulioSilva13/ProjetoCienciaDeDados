{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5b7b662a",
      "metadata": {
        "id": "5b7b662a"
      },
      "source": [
        "## **Descrição do projeto**\n",
        "> O projeto tem o foco em desenvolver um modelo capaz de medir a taxa de evasão dos alunos do curso de Ciência da Computação da Universidade Federal de Viçosa - Campus Florestal,  onde são classificados de acordo com alguns parâmetros como idade, gênero, data de ingresso no curso, raça, cidade onde vivia antes de se mudar para as aulas, nota obtida no ENEM, CRA, modalidade de ingresso e o número de reprovações."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Bibliotecas utilizadas**"
      ],
      "metadata": {
        "id": "XBRyOkZ1DwnY"
      },
      "id": "XBRyOkZ1DwnY"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-Levenshtein\n",
        "!pip install fuzzywuzzy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vkQEOL5ctuP",
        "outputId": "0de5589a-ae36-44d7-e910-1f2f25da5d36"
      },
      "id": "2vkQEOL5ctuP",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-Levenshtein\n",
            "  Downloading python_Levenshtein-0.21.0-py3-none-any.whl (9.4 kB)\n",
            "Collecting Levenshtein==0.21.0 (from python-Levenshtein)\n",
            "  Downloading Levenshtein-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (174 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.1/174.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<4.0.0,>=2.3.0 (from Levenshtein==0.21.0->python-Levenshtein)\n",
            "  Downloading rapidfuzz-3.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
            "Successfully installed Levenshtein-0.21.0 python-Levenshtein-0.21.0 rapidfuzz-3.0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0b02d5a",
      "metadata": {
        "id": "d0b02d5a"
      },
      "outputs": [],
      "source": [
        "### NÃO REMOVA ESSA CÉLULA!! ###\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import unicodedata\n",
        "from fuzzywuzzy import fuzz\n",
        "from fuzzywuzzy import process"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Leitura dos dados**"
      ],
      "metadata": {
        "id": "9mhIGSrGEHlL"
      },
      "id": "9mhIGSrGEHlL"
    },
    {
      "cell_type": "code",
      "source": [
        "### NÃO REMOVA ESSA CÉLULA!! ###\n",
        "!wget https://raw.githubusercontent.com/ThulioSilva13/ProjetoCienciaDeDados/main/dadosEstudantesUFV.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kT8WgQTaE8Fc",
        "outputId": "4f8da427-71a1-4af1-dbbd-8a3a429ee716"
      },
      "id": "kT8WgQTaE8Fc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-18 19:26:00--  https://raw.githubusercontent.com/ThulioSilva13/ProjetoCienciaDeDados/main/dadosEstudantesUFV.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2023-05-18 19:26:01 ERROR 404: Not Found.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dados = pd.read_csv('./dadosEstudantesUFV.csv')\n",
        "dados"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "L8LpNR2tFIuU",
        "outputId": "cd3e81de-f26a-471d-d090-f27cd73b4b79"
      },
      "id": "L8LpNR2tFIuU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-b747f70a6b49>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdados\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./dadosEstudantesUFV.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdados\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './dadosEstudantesUFV.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a7650c3",
      "metadata": {
        "id": "0a7650c3"
      },
      "source": [
        "## **Análise inicial dos dados**\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Inicialmente foi feita uma análise inicial dos atributos, observando fatores como o nome da coluna, o tipo de dado, os valores, dentre outros aspectos. Abaixo são listadas as observações:\n",
        "\n",
        "> 1. Ao analisar os dados, percebeu-se que alguns possuem incompatibilidade em alguns campos, como por exemplo:\n",
        " - Não são todos os alunos que possuem valores na coluna contendo a nota do ENEM\n",
        " - Alguns campos que deveriam ter o preenchimento obrigatório, como as colunas Sexo e UF_Nascimento, estão valores NaN.\n",
        "  - Alguns alunos possuem modalidade de ingresso com valor igual a zero. Desse modo, após pesquisar sobre o significado da modadlidade 0, descobriu-se que se refere ao campo de \"Ampla Concorrência\", entretanto, o valor de modalidade 9 também se refere a esse mesmo campo. Portanto, vale observar essa semelhança entre os dados para que futuramente no projeto evite falhas na observação e conclusão na análise desses dados.\n",
        "\n",
        "> 2. Outra observação realizada, foi a relação entre a modalidade de ingresso e a nota obtida no ENEM, alguns alunos tem o campo preenchido com a nota do ENEM que usaram quando entraram na universidade, mas porém não consta em qual modalidade ele foi classificado. O mesmo se aplica no caso contrário, alguns alunos não possuem a nota do ENEM, mas na coluna da modalidade de ingresso, consta um valor.\n",
        "\n",
        "> 3. Ao examinarmos o campo Situacao_Aluno, é possível perceber que ele possui diversos tipos de valores, como por exemplo, Conclusão, Desligamento, Abandono, Transferência, entre outros. Já ao observarmos o campo Situacao_Aluno_Agrupado, os valores se resumem a Conclusão, Evasão, Retenção e Matriculado. Após análises, percebeu-se que uma coluna tem relação direta com a outra, pois:\n",
        "  - O valor Conclusão no campo Situacao_Aluno_Agrupado, se refere também aos valores Conclusão de Situacao_Aluno que indicam que o aluno concluiu o curso\n",
        "  - Evasão corresponde aos alunos que abandonaram o curso\n",
        "  - Matriculado caracteriza os alunos que ainda estão cursando\n",
        "  - Retenção se refere aos alunos que ainda estão cursando, mas que por algum motivo, não estão tendo aulas\n",
        "\n",
        ">   Foi concluído então que o campo Situacao_Aluno_Agrupado é uma versão resumida do campo Situacao_Aluno, com valores agrupados que indicam a situação atual do aluno no curso. Essa análise é importante para compreender melhor os dados e para tomar decisões com base nessas informações, além de que entender a relação entre as diferentes colunas pode ajudar a identificar tendências."
      ],
      "metadata": {
        "id": "-yYE7O28HeVv"
      },
      "id": "-yYE7O28HeVv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Perguntas que guiarão o projeto**"
      ],
      "metadata": {
        "id": "XC7xErpFIgB8"
      },
      "id": "XC7xErpFIgB8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Inicialmente, existem 10 perguntas que guiarão o projeto e que pretendemos responder durante o desenvolvimento do modelo, sendo elas:\n",
        "\n",
        " -  O CRA segue uma distribuição normal?\n",
        " (Histograma)\n",
        "\n",
        " - Avaliar se o gênero influencia na evasão através de análises da porcentagem de meninas que evadiram em comparação com o valor percentual de meninos que evadiram.\n",
        " (Teste de hipótese com algumas estatísticas descritivas)\n",
        "\n",
        " - Número médio de alunos que ingressaram no curso durante a pandemia de COVID-19, onde se espera entender se o método de ensino remoto influenciou ou não na decisão de saída do curso.\n",
        " (Gráfico de linhas)\n",
        "\n",
        " - Esperamos prever a quantidade de alunos, em porcentagem, por modalidade de ingresso abandonaram o curso.\n",
        " (Gráfico de pizza)\n",
        "\n",
        " - Visamos compreender se alunos que vieram de escolas públicas encontram mais dificuldades e isso os levam a abandonar o curso.\n",
        " (Teste de hipótese)\n",
        "\n",
        " - Visamos calcular o valor médio de reprovações que os alunos que evadiram tiveram e analisar se há um padrão ou intervalo de números que aparecem de forma frequente.\n",
        " (Estatística descritiva, calcular média)\n",
        "\n",
        " - Qual a média de idade das pessoas que decidiram abandonar o curso. O aluno ser mais velho ou mais novo influencia na decisão de saída?\n",
        " (Estatística descritiva, calcular média)\n",
        "\n",
        " - Existe alguma relação entre a nota do ENEM e a evasão do curso?\n",
        "(Comparar Gráficos entre relação nota e evasão)\n",
        "\n",
        "\n",
        " - É possível afirmar que os alunos abandonam o curso por serem de algum estado diferente de Minas Gerais, onde o campus se localiza?\n",
        "(Gráfico e estatística descritiva)\n",
        "\n",
        "\n",
        " - Realizar o cálculo de estatísticas descritivas sobre o CRA de alunos que abandonaram o curso em comparação com o CRA de alunos que concluíram e dessa forma, tentamos estabelecer uma relação de influência entre o CRA e a evasão.\n",
        " \n",
        "\n",
        " - Através do cálculo da média do CRA dos alunos de Ciência da Computação, esperamos ser possível classificar se uma amostra pertence ou não a população que representa os alunos do curso citado."
      ],
      "metadata": {
        "id": "YAufkfTFIm2q"
      },
      "id": "YAufkfTFIm2q"
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Criar um dataFrame para salvar apenas alunos que já saíram do curso.\n",
        "2) Verificar campos que estejam com valores NULL ou NaN\n",
        "3) Definir uma valor só pra ampla concorrência(ao invés de 0 e 9)\n",
        "4) Cursos que são o mesmo porém com dois ou mais nomes diferentes\n",
        "5) Remover alunos que não ingressaram via ENEM\n",
        "6) Remover alunos que ingressaram sem nenhuma modalidade\n",
        "7) Remover cidades com problemas "
      ],
      "metadata": {
        "id": "9h1AuUQuPhzF"
      },
      "id": "9h1AuUQuPhzF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Formatação e limpeza dos dados**"
      ],
      "metadata": {
        "id": "dzzyevF5GmSx"
      },
      "id": "dzzyevF5GmSx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Essa etapa envolve entender os atributos e objetos dos dados, os tipos de cada atributo, o domínio de cada atributo,\n",
        "verificar e identificar possíveis ruídos ou informações ausentes, criar novos atributos se necessário, formatar valores, juntar conjuntos de dados, dentre outras atividades."
      ],
      "metadata": {
        "id": "HPwuZKJkHnHk"
      },
      "id": "HPwuZKJkHnHk"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_6FGMU2KPblf"
      },
      "id": "_6FGMU2KPblf"
    },
    {
      "cell_type": "code",
      "source": [
        "def strip_accents(text):\n",
        "    try:\n",
        "        text = unicode(text, 'utf-8')\n",
        "    except NameError:\n",
        "        pass\n",
        "    text = unicodedata.normalize('NFD', text)\n",
        "    text = text.encode('ascii', 'ignore')\n",
        "    text = text.decode(\"utf-8\")\n",
        "    return str(text)\n",
        "\n",
        "def standardize_strings(column, threshold=80):\n",
        "    standardized_strings = []\n",
        "    for string in column:\n",
        "        standardized = False\n",
        "        for standard in standardized_strings:\n",
        "            similarity = fuzz.ratio(string, standard)\n",
        "            if similarity >= threshold:\n",
        "                column.replace(string, standard, inplace=True)\n",
        "                standardized = True\n",
        "                break\n",
        "        \n",
        "        if not standardized:\n",
        "            standardized_strings.append(string)\n",
        "\n",
        "    return column\n",
        "\n",
        "def merge_entries(course_name):\n",
        "    if course_name.endswith(' - Licenciatura'):\n",
        "        return course_name[:-len(' - Licenciatura')]\n",
        "    else:\n",
        "        return course_name\n",
        "\n",
        "def remove_suffix(entry):\n",
        "    return entry.split(' - ')[0]\n",
        "\n",
        "df = pd.read_csv('a.csv',header=0)\n",
        "print(df.columns.values)\n",
        "\n",
        "# remove valores nulos\n",
        "df = df.dropna()\n",
        "\n",
        "# na database, existem alunos nascidos após 2015\n",
        "# supos-se que isso não faz sentido\n",
        "df = df[df[\"Ano_Nascimento\"] < 2015]\n",
        "\n",
        "# alunos cujo campo de estado estão em branco\n",
        "# foram removidos para propositos da análise\n",
        "df= df[df[\"UF_Nascimento\"] != \" \"]\n",
        "\n",
        "# remove acentos, espaços e passa tudo para lowercase\n",
        "df['Municipio_Nascimento'] = df['Municipio_Nascimento'].apply(lambda x: strip_accents(x).strip().lower())\n",
        "df['Situacao_Aluno'] = df['Situacao_Aluno'].apply(lambda x: strip_accents(x).strip().lower())\n",
        "\n",
        "# une cursos de licenciatura com sufixo específico ' - Licenciatura'\n",
        "# proprio de cursos em Florestal\n",
        "df['Curso'] = df['Curso'].apply(merge_entries)\n",
        "df['Curso'] = df['Curso'].apply(lambda x: x.strip())\n",
        "\n",
        "# renomeia municipios com sufixos de estado\n",
        "# ex \"vicosa\", \"vicosa - mg\" \n",
        "df['Municipio_Nascimento'] = df['Municipio_Nascimento'].apply(remove_suffix)\n",
        "\n",
        "# cria um df onde só existem alunos que evadiram ou formam\n",
        "df_filtro = df[(df[\"Situacao_Aluno_Agrupada\"] == \"Conclusão\") | (df[\"Situacao_Aluno_Agrupada\"] == \"Evasão\")]\n",
        "\n",
        "# une municipios de nome similar a partir de threshold\n",
        "# ex: \"vcosa\", \"vicosa\"\n",
        "standardized_column = standardize_strings(df['Municipio_Nascimento'], threshold=80)\n",
        "df['Municipio_Nascimento'] = standardized_column\n",
        "\n",
        "'''\n",
        "res = []\n",
        "for i in (df[\"Ano_Nascimento\"].unique()):\n",
        "\tres.append(i)\n",
        "\n",
        "print(sorted(res))\n",
        "'''"
      ],
      "metadata": {
        "id": "s01R0j9ILXw1"
      },
      "id": "s01R0j9ILXw1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Estatísticas descritivas sobre os dados**\n"
      ],
      "metadata": {
        "id": "ugm1CIUoG_i-"
      },
      "id": "ugm1CIUoG_i-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Nesta etapa, o grupo também irá gerar estatísticas descritivas, gráficos e tabelas para conhecer os dados. Todo conhecimento importante extraído deverá ser documentado e discutido. Nesta etapa, o objetivo é responder parte das perguntas elaboradas. Lembrem-se que novos questionamentos podem surgir e devem ser documentados."
      ],
      "metadata": {
        "id": "KqMe6Fm8Hq9K"
      },
      "id": "KqMe6Fm8Hq9K"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}